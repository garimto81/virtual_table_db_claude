# AI 기반 스트림덱 스위칭 시스템 개발 프로세스

## 🚀 Phase 1: 프로젝트 기반 구축 (2주)

### 1.1 개발 환경 구축
```bash
# 1단계: 저장소 설정
git init hybrid-switcher-ai
cd hybrid-switcher-ai

# 프로젝트 구조 생성
mkdir -p {ai-engine,companion-plugin,bridge-service,web-interface,tests,docs,deployment}

# 2단계: Python 환경 (AI 엔진)
pyenv install 3.11.0
pyenv local 3.11.0
pip install poetry

# poetry 프로젝트 초기화
cd ai-engine
poetry init
poetry add torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
poetry add opencv-python fastapi uvicorn websockets redis
poetry add --group dev pytest black flake8 mypy

# 3단계: Node.js 환경 (Companion 플러그인)
cd ../companion-plugin
npm init -y
npm install @companion-module/base ws
npm install --save-dev typescript @types/node @types/ws
```

### 1.2 기본 아키텍처 설정
```yaml
# docker-compose.yml
version: '3.8'
services:
  ai-engine:
    build: ./ai-engine
    ports: ["8001:8001"]
    volumes: ["./models:/app/models"]
    environment:
      - CUDA_VISIBLE_DEVICES=0
    
  bridge-service:
    build: ./bridge-service
    ports: ["8080:8080"]
    depends_on: [ai-engine, redis]
    
  redis:
    image: redis:7-alpine
    ports: ["6379:6379"]
    
  web-interface:
    build: ./web-interface
    ports: ["3000:3000"]
```

## 🧠 Phase 2: AI 모델 개발 (4-6주)

### 2.1 데이터 수집 및 전처리
```python
# Week 1-2: 데이터 파이프라인 구축
class DataCollectionPipeline:
    def __init__(self):
        self.video_sources = []
        self.annotation_tools = AnnotationTool()
        
    def collect_poker_videos(self):
        """포커 게임 영상 수집"""
        sources = [
            "twitch_poker_streams",
            "youtube_poker_content", 
            "recorded_live_games"
        ]
        return self.download_and_process(sources)
        
    def create_annotations(self, videos):
        """수동 라벨링 도구로 학습 데이터 생성"""
        annotations = []
        for video in videos:
            # 중요 순간 타임스탬프 마킹
            key_moments = self.annotation_tools.mark_key_moments(video)
            # 게임 상태 라벨링
            game_states = self.annotation_tools.label_game_states(video)
            annotations.append({
                'video': video,
                'key_moments': key_moments,
                'game_states': game_states
            })
        return annotations
```

### 2.2 비전 모델 개발
```python
# Week 2-3: 게임 요소 감지 모델
class PokerVisionModel(nn.Module):
    def __init__(self):
        super().__init__()
        # YOLOv8 백본 사용
        self.backbone = YOLO('yolov8n.pt')
        self.poker_head = self.build_poker_detection_head()
        
    def build_poker_detection_head(self):
        """포커 특화 감지 헤드"""
        return nn.Sequential(
            nn.Conv2d(512, 256, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(256, len(POKER_CLASSES), 1)  # 카드, 칩, 플레이어 등
        )
        
# 훈련 스크립트
def train_vision_model():
    model = PokerVisionModel()
    trainer = pl.Trainer(
        max_epochs=100,
        gpus=1,
        callbacks=[ModelCheckpoint(), EarlyStopping()]
    )
    trainer.fit(model, train_dataloader, val_dataloader)
```

### 2.3 게임 상황 이해 모델
```python
# Week 3-4: 컨텍스트 분석 모델
class GameContextTransformer(nn.Module):
    def __init__(self, d_model=512):
        super().__init__()
        self.transformer = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(d_model, nhead=8),
            num_layers=6
        )
        self.situation_classifier = nn.Linear(d_model, NUM_SITUATIONS)
        
    def analyze_game_sequence(self, game_events):
        """게임 이벤트 시퀀스에서 상황 분석"""
        embedded = self.embed_game_events(game_events)
        context = self.transformer(embedded)
        situation = self.situation_classifier(context[-1])
        return situation
```

### 2.4 스위칭 예측 모델
```python
# Week 4-5: 스위칭 타이밍 예측
class SwitchingPredictor(nn.Module):
    def __init__(self):
        super().__init__()
        self.lstm = nn.LSTM(input_size=256, hidden_size=512, num_layers=3)
        self.attention = MultiHeadAttention(512, num_heads=8)
        self.predictor = nn.Linear(512, len(SWITCHING_ACTIONS))
        
    def predict_switching_action(self, game_history, current_state):
        """다음 스위칭 액션과 타이밍 예측"""
        lstm_out, _ = self.lstm(game_history)
        attended = self.attention(lstm_out, current_state)
        prediction = self.predictor(attended)
        return {
            'action': prediction.argmax(-1),
            'confidence': F.softmax(prediction, -1).max(),
            'timing': self.estimate_optimal_timing(prediction)
        }
```

## 🔌 Phase 3: Companion 플러그인 개발 (3-4주)

### 3.1 기본 플러그인 구조
```typescript
// Week 6: Companion 플러그인 기본 구조
// companion-plugin/src/index.ts
import { InstanceBase, InstanceStatus } from '@companion-module/base'

export class HybridSwitcherInstance extends InstanceBase<Config> {
    private aiConnection: WebSocket | null = null
    private currentSuggestion: AISuggestion | null = null
    
    async init(config: Config): Promise<void> {
        this.config = config
        this.updateStatus(InstanceStatus.Connecting)
        
        await this.connectToAIService()
        this.initActions()
        this.initFeedbacks()
        this.initPresets()
        
        this.updateStatus(InstanceStatus.Ok)
    }
    
    private async connectToAIService(): Promise<void> {
        const wsUrl = `ws://${this.config.host}:${this.config.port}/ws`
        this.aiConnection = new WebSocket(wsUrl)
        
        this.aiConnection.onmessage = (event) => {
            const message = JSON.parse(event.data)
            this.handleAIMessage(message)
        }
    }
}
```

### 3.2 동적 UI 개발
```typescript
// Week 7: 버튼 상태 관리 시스템
class ButtonManager {
    updateSuggestionButtons(suggestion: AISuggestion): void {
        // AI 신뢰도에 따른 동적 색상
        const confidenceColor = this.getConfidenceColor(suggestion.confidence)
        
        this.setButtonState('accept_suggestion', {
            text: `수락 ${Math.round(suggestion.confidence * 100)}%`,
            bgcolor: confidenceColor,
            blink: suggestion.confidence > 0.9
        })
        
        // 카운트다운 타이머 시작
        if (suggestion.auto_execute) {
            this.startCountdown('accept_suggestion', suggestion.timeout)
        }
    }
    
    private startCountdown(buttonId: string, seconds: number): void {
        let remaining = seconds
        const interval = setInterval(() => {
            if (remaining <= 0) {
                clearInterval(interval)
                this.executeAutoAction(buttonId)
                return
            }
            this.updateButtonText(buttonId, `수락 (${remaining}s)`)
            remaining--
        }, 1000)
    }
}
```

### 3.3 플러그인 패키징
```json
// Week 8: 배포 준비
{
  "name": "@hybrid-switcher/companion-plugin",
  "version": "1.0.0",
  "main": "dist/index.js",
  "scripts": {
    "build": "tsc",
    "package": "npm pack",
    "install-companion": "cp *.tgz ~/.companion/plugins/"
  },
  "companion": {
    "minimumVersion": "3.0.0",
    "category": "Broadcasting"
  }
}
```

## 🌉 Phase 4: 통합 시스템 개발 (3-4주)

### 4.1 브리지 서비스 개발
```python
# Week 9: AI 엔진과 Companion 간 브리지
from fastapi import FastAPI, WebSocket
import asyncio
import json

app = FastAPI()

class BridgeService:
    def __init__(self):
        self.ai_client = AIEngineClient()
        self.companion_connections = set()
        
    async def handle_companion_connection(self, websocket: WebSocket):
        await websocket.accept()
        self.companion_connections.add(websocket)
        
        try:
            while True:
                # Companion에서 메시지 수신
                message = await websocket.receive_text()
                await self.handle_companion_message(json.loads(message))
        except:
            self.companion_connections.remove(websocket)
            
    async def handle_ai_suggestion(self, suggestion):
        """AI 제안을 모든 연결된 Companion으로 전송"""
        message = json.dumps({
            'type': 'ai_suggestion',
            'data': suggestion
        })
        
        for connection in self.companion_connections:
            await connection.send_text(message)

@app.websocket("/ws/companion")
async def companion_websocket(websocket: WebSocket):
    bridge = BridgeService()
    await bridge.handle_companion_connection(websocket)
```

### 4.2 실시간 처리 파이프라인
```python
# Week 10: 실시간 비디오 처리
import asyncio
import cv2
from concurrent.futures import ThreadPoolExecutor

class RealTimeProcessor:
    def __init__(self):
        self.ai_model = load_trained_model()
        self.executor = ThreadPoolExecutor(max_workers=4)
        self.frame_queue = asyncio.Queue(maxsize=30)
        
    async def process_video_stream(self, video_source):
        """실시간 비디오 스트림 처리"""
        cap = cv2.VideoCapture(video_source)
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
                
            # 비동기 AI 추론
            loop = asyncio.get_event_loop()
            future = loop.run_in_executor(
                self.executor, 
                self.ai_model.inference, 
                frame
            )
            
            # 결과를 기다리지 않고 다음 프레임 처리
            asyncio.create_task(self.handle_inference_result(future))
            
            await asyncio.sleep(1/30)  # 30 FPS
            
    async def handle_inference_result(self, future):
        result = await future
        if result['confidence'] > 0.7:
            await self.send_suggestion_to_companion(result)
```

## 🧪 Phase 5: 테스트 및 최적화 (2-3주)

### 5.1 단위 테스트
```python
# Week 11: AI 모델 테스트
import pytest
import torch

class TestAIModels:
    def test_vision_model_inference(self):
        model = PokerVisionModel()
        dummy_frame = torch.randn(1, 3, 720, 1280)
        
        with torch.no_grad():
            result = model(dummy_frame)
            
        assert result['detections'].shape[0] > 0
        assert 0 <= result['confidence'].item() <= 1
        
    def test_prediction_latency(self):
        model = PokerVisionModel().cuda()
        dummy_input = torch.randn(1, 3, 720, 1280).cuda()
        
        import time
        start_time = time.time()
        
        for _ in range(100):
            _ = model(dummy_input)
            torch.cuda.synchronize()
            
        avg_time = (time.time() - start_time) / 100
        assert avg_time < 0.05  # 50ms 이하
```

### 5.2 통합 테스트
```typescript
// Companion 플러그인 테스트
describe('Companion Integration', () => {
    let mockAIService: MockAIService
    let instance: HybridSwitcherInstance
    
    beforeEach(async () => {
        mockAIService = new MockAIService()
        await mockAIService.start()
        
        instance = new HybridSwitcherInstance()
        await instance.init({
            host: 'localhost',
            port: mockAIService.port
        })
    })
    
    test('should handle AI suggestions', async () => {
        const suggestion = {
            action: 'camera_switch',
            confidence: 0.85,
            timeout: 10
        }
        
        mockAIService.sendSuggestion(suggestion)
        await new Promise(resolve => setTimeout(resolve, 100))
        
        expect(instance.getCurrentSuggestion()).toEqual(suggestion)
    })
})
```

### 5.3 성능 최적화
```python
# Week 12: 성능 최적화
class OptimizedInference:
    def __init__(self, model_path):
        # TensorRT 최적화
        self.model = torch.jit.load(model_path)
        self.model = torch_tensorrt.compile(self.model)
        
        # 메모리 풀링
        self.memory_pool = MemoryPool()
        
    @torch.no_grad()
    async def optimized_inference(self, frame):
        # 반정밀도 연산
        with torch.cuda.amp.autocast():
            result = self.model(frame.half())
            
        return result.float()
```

## 🚀 Phase 6: 배포 및 운영 (1-2주)

### 6.1 Docker 컨테이너화
```dockerfile
# ai-engine/Dockerfile
FROM nvidia/cuda:11.8-runtime-ubuntu20.04

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8001

CMD ["python", "-m", "ai_engine.main"]
```

### 6.2 CI/CD 파이프라인
```yaml
# .github/workflows/deploy.yml
name: Deploy

on:
  push:
    branches: [main]

jobs:
  test-and-deploy:
    runs-on: ubuntu-latest-gpu
    steps:
      - uses: actions/checkout@v3
      
      - name: Run tests
        run: |
          python -m pytest ai-engine/tests/
          npm test --prefix companion-plugin
          
      - name: Build containers
        run: docker-compose build
        
      - name: Deploy to staging
        run: |
          docker-compose -f docker-compose.staging.yml up -d
          
      - name: Run integration tests
        run: python integration-tests/test_full_system.py
        
      - name: Deploy to production
        if: success()
        run: |
          docker-compose -f docker-compose.prod.yml up -d
```

## 📊 개발 일정 요약

| Phase | 기간 | 주요 산출물 | 리소스 |
|-------|------|-------------|---------|
| Phase 1 | 2주 | 개발환경, 기본 구조 | 1명 (DevOps) |
| Phase 2 | 4-6주 | AI 모델, 학습 파이프라인 | 2명 (AI 엔지니어) |
| Phase 3 | 3-4주 | Companion 플러그인 | 1명 (Frontend) |
| Phase 4 | 3-4주 | 통합 시스템, 브리지 | 1명 (Backend) |
| Phase 5 | 2-3주 | 테스트, 최적화 | 전체 팀 |
| Phase 6 | 1-2주 | 배포, 운영 | 1명 (DevOps) |

**총 개발 기간**: 15-21주 (약 4-5개월)
**필요 인력**: 5명 (AI 엔지니어 2명, Backend 1명, Frontend 1명, DevOps 1명)

## 🎯 성공 기준

### 기술적 목표
- AI 예측 정확도: 85% 이상
- 시스템 응답 시간: 50ms 이하
- 가동률: 99.9% 이상

### 비즈니스 목표
- 운영자 피로도: 70% 감소
- 방송 품질 향상: 측정 가능한 지표
- 사용자 만족도: 4.5/5.0 이상

이 개발 프로세스를 통해 완전한 AI 기반 스트림덱 스위칭 시스템을 구축할 수 있습니다!